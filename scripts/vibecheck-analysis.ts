#!/usr/bin/env npx tsx
/**
 * Vibecheck Performance Analysis Script
 *
 * Fetches data from GitHub across all repos where vibecheck is installed
 * and produces analysis reports for validating vibecheck's performance.
 *
 * Usage: npx tsx scripts/vibecheck-analysis.ts [--question=1,2,3,4,5]
 */

import { execSync } from 'child_process';
import * as fs from 'fs';
import * as path from 'path';

// All repos with vibecheck installed
const REPOS = [
  'WolffM/vibedispatch',
  'WolffM/jobPlatform',
  'WolffM/hadoku-task',
  'WolffM/hadoku-task-mobile',
  'WolffM/vibecheck',
  'WolffM/hadoku_site',
  'WolffM/hadoku-watchparty',
  'WolffM/hadoku-resume-bot',
  'WolffM/hadoku-printTool',
  'WolffM/hadoku-contact-ui',
  'WolffM/OSS-Issue-Aggregator',
  'WolffM/gameToCalender',
  'WolffM/epicmediabattle',
  'WolffM/StickerMaker',
  'WolffM/seaborn-ranked-animated',
  'WolffM/TTRPGSessionSummarizer',
  'WolffM/fileSystemAgent',
  'WolffM/ArchiveBot',
  'WolffM/checkmage-bot',
  'WolffM/mtgProxyPrint',
];

const OUTPUT_DIR = '.vibecheck-analysis';

interface Issue {
  number: number;
  title: string;
  body: string;
  state: string;
  labels: string[];
  createdAt: string;
  closedAt: string | null;
  repo: string;
  url: string;
}

interface PullRequest {
  number: number;
  title: string;
  body: string;
  state: string;
  merged: boolean;
  mergedAt: string | null;
  closedAt: string | null;
  labels: string[];
  repo: string;
  url: string;
  additions: number;
  deletions: number;
  changedFiles: number;
  diff?: string;
}

interface WorkflowRun {
  id: number;
  name: string;
  conclusion: string;
  status: string;
  headBranch: string;
  headSha: string;
  event: string;
  createdAt: string;
  repo: string;
  url: string;
}

// Helper to run gh CLI commands
function gh(args: string, options: { json?: string; repo?: string } = {}): string {
  let cmd = `gh ${args}`;
  if (options.repo) {
    cmd += ` --repo ${options.repo}`;
  }
  if (options.json) {
    cmd += ` --json ${options.json}`;
  }

  try {
    return execSync(cmd, { encoding: 'utf-8', maxBuffer: 50 * 1024 * 1024 });
  } catch (error: unknown) {
    const execError = error as { stderr?: string; message?: string };
    console.error(`Error running: ${cmd}`);
    console.error(execError.stderr || execError.message);
    return '[]';
  }
}

function ensureOutputDir(): void {
  if (!fs.existsSync(OUTPUT_DIR)) {
    fs.mkdirSync(OUTPUT_DIR, { recursive: true });
  }
}

function writeReport(filename: string, content: string): void {
  ensureOutputDir();
  const filepath = path.join(OUTPUT_DIR, filename);
  fs.writeFileSync(filepath, content);
  console.log(`  Written: ${filepath}`);
}

function writeJson(filename: string, data: unknown): void {
  ensureOutputDir();
  const filepath = path.join(OUTPUT_DIR, filename);
  fs.writeFileSync(filepath, JSON.stringify(data, null, 2));
  console.log(`  Written: ${filepath}`);
}

// ============================================================================
// Q1: Bundleable Issues Analysis
// Look for issues that could be grouped together (e.g., multiple .md formatting issues)
// ============================================================================
async function analyzeQ1_BundleableIssues(): Promise<void> {
  console.log('\n========================================');
  console.log('Q1: Analyzing Bundleable Issues');
  console.log('========================================\n');

  const allIssues: Issue[] = [];

  for (const repo of REPOS) {
    console.log(`  Fetching issues from ${repo}...`);
    const result = gh(
      'issue list --state all --limit 500',
      {
        repo,
        json: 'number,title,body,state,labels,createdAt,closedAt,url'
      }
    );

    try {
      const issues = JSON.parse(result) as Array<{
        number: number;
        title: string;
        body: string;
        state: string;
        labels: Array<{ name: string }>;
        createdAt: string;
        closedAt: string | null;
        url: string;
      }>;
      for (const issue of issues) {
        allIssues.push({
          ...issue,
          labels: issue.labels.map((l) => l.name),
          repo,
        });
      }
    } catch {
      console.error(`  Failed to parse issues from ${repo}`);
    }
  }

  // Filter for vibecheck-created issues (look for common patterns)
  const vibecheckIssues = allIssues.filter(
    (i) =>
      i.labels.some((l) => l.includes('vibecheck') || l.includes('static-analysis')) ||
      i.title.includes('[vibecheck]') ||
      i.body?.includes('vibecheck') ||
      i.body?.includes('Generated by vibecheck')
  );

  console.log(`\n  Total issues found: ${allIssues.length}`);
  console.log(`  Vibecheck issues found: ${vibecheckIssues.length}`);

  // Group issues by patterns
  const groupedByFileType: Record<string, Issue[]> = {};
  const groupedByRule: Record<string, Issue[]> = {};
  const groupedByRepo: Record<string, Issue[]> = {};

  for (const issue of vibecheckIssues) {
    // Group by file extension mentioned in title/body
    const fileExtMatch = issue.title.match(/\.(md|ts|js|py|json|yml|yaml|tsx|jsx)/i);
    if (fileExtMatch) {
      const ext = fileExtMatch[1].toLowerCase();
      if (!groupedByFileType[ext]) groupedByFileType[ext] = [];
      groupedByFileType[ext].push(issue);
    }

    // Group by rule ID (look for common rule patterns)
    const ruleMatch = issue.title.match(/\[([^\]]+)\]/) || issue.body?.match(/Rule:\s*`?([^`\n]+)`?/);
    if (ruleMatch) {
      const rule = ruleMatch[1];
      if (!groupedByRule[rule]) groupedByRule[rule] = [];
      groupedByRule[rule].push(issue);
    }

    // Group by repo
    if (!groupedByRepo[issue.repo]) groupedByRepo[issue.repo] = [];
    groupedByRepo[issue.repo].push(issue);
  }

  // Generate report
  let report = '# Q1: Bundleable Issues Analysis\n\n';
  report += `**Analysis Date:** ${new Date().toISOString()}\n\n`;
  report += `**Total Issues Analyzed:** ${allIssues.length}\n`;
  report += `**Vibecheck Issues Found:** ${vibecheckIssues.length}\n\n`;

  report += '## Issues by File Type (Bundling Candidates)\n\n';
  report += 'These issues target the same file types and could potentially be bundled:\n\n';

  const sortedByFileType = Object.entries(groupedByFileType)
    .sort((a, b) => b[1].length - a[1].length);

  for (const [ext, issues] of sortedByFileType) {
    if (issues.length > 1) {
      report += `### .${ext} files (${issues.length} issues)\n\n`;
      report += '| Repo | Issue | Title |\n';
      report += '|------|-------|-------|\n';
      for (const issue of issues.slice(0, 20)) {
        report += `| ${issue.repo.split('/')[1]} | [#${issue.number}](${issue.url}) | ${issue.title.slice(0, 60)}... |\n`;
      }
      if (issues.length > 20) {
        report += `| ... | ... | *(${issues.length - 20} more)* |\n`;
      }
      report += '\n';
    }
  }

  report += '## Issues by Rule (Bundling Candidates)\n\n';
  report += 'These issues are for the same rule and could be auto-bundled:\n\n';

  const sortedByRule = Object.entries(groupedByRule)
    .sort((a, b) => b[1].length - a[1].length);

  for (const [rule, issues] of sortedByRule) {
    if (issues.length > 1) {
      report += `### Rule: \`${rule}\` (${issues.length} issues)\n\n`;
      const repos = [...new Set(issues.map((i) => i.repo))];
      report += `Affects repos: ${repos.join(', ')}\n\n`;
      report += '| Repo | Issue | State |\n';
      report += '|------|-------|-------|\n';
      for (const issue of issues.slice(0, 10)) {
        report += `| ${issue.repo.split('/')[1]} | [#${issue.number}](${issue.url}) | ${issue.state} |\n`;
      }
      report += '\n';
    }
  }

  report += '## Recommendations\n\n';
  report += '1. **Bundle .md issues:** Consider grouping markdown formatting issues into single "Fix markdown formatting" issues\n';
  report += '2. **Rule-based bundling:** Issues for the same rule in a repo could be combined\n';
  report += '3. **Threshold suggestion:** Only create separate issues if changes affect >N lines or >N files\n';

  writeReport('q1-bundleable-issues.md', report);
  writeJson('q1-issues-data.json', {
    totalIssues: allIssues.length,
    vibecheckIssues: vibecheckIssues.length,
    byFileType: Object.fromEntries(
      Object.entries(groupedByFileType).map(([k, v]) => [k, v.length])
    ),
    byRule: Object.fromEntries(
      Object.entries(groupedByRule).map(([k, v]) => [k, v.length])
    ),
    issues: vibecheckIssues,
  });
}

// ============================================================================
// Q2: Autofix Candidates Analysis
// Look at merged PRs to find predictable resolution patterns
// ============================================================================
async function analyzeQ2_AutofixCandidates(): Promise<void> {
  console.log('\n========================================');
  console.log('Q2: Analyzing Autofix Candidates');
  console.log('========================================\n');

  const allPRs: PullRequest[] = [];

  for (const repo of REPOS) {
    console.log(`  Fetching merged PRs from ${repo}...`);
    const result = gh(
      'pr list --state merged --limit 200',
      {
        repo,
        json: 'number,title,body,state,labels,mergedAt,closedAt,url,additions,deletions,changedFiles',
      }
    );

    try {
      const prs = JSON.parse(result) as Array<{
        number: number;
        title: string;
        body: string;
        state: string;
        labels: Array<{ name: string }>;
        mergedAt: string | null;
        closedAt: string | null;
        url: string;
        additions: number;
        deletions: number;
        changedFiles: number;
      }>;
      for (const pr of prs) {
        allPRs.push({
          ...pr,
          merged: true,
          labels: pr.labels.map((l) => l.name),
          repo,
        });
      }
    } catch {
      console.error(`  Failed to parse PRs from ${repo}`);
    }
  }

  // Filter for vibecheck-related or copilot-created PRs
  const vibecheckPRs = allPRs.filter(
    (pr) =>
      pr.labels.some((l) =>
        l.includes('vibecheck') ||
        l.includes('copilot') ||
        l.includes('bot')
      ) ||
      pr.title.toLowerCase().includes('fix') ||
      pr.body?.includes('vibecheck') ||
      pr.body?.includes('Fixes #')
  );

  console.log(`\n  Total merged PRs found: ${allPRs.length}`);
  console.log(`  Vibecheck-related PRs: ${vibecheckPRs.length}`);

  // Fetch diffs for small PRs (potential autofix candidates)
  const smallPRs = vibecheckPRs.filter(
    (pr) => pr.changedFiles <= 5 && pr.additions + pr.deletions <= 50
  );

  console.log(`  Small PRs (potential autofix): ${smallPRs.length}`);
  console.log(`  Fetching diffs for small PRs...`);

  const prsWithDiffs: PullRequest[] = [];
  for (const pr of smallPRs.slice(0, 50)) {
    try {
      const diff = execSync(
        `gh pr diff ${pr.number} --repo ${pr.repo}`,
        { encoding: 'utf-8', maxBuffer: 10 * 1024 * 1024 }
      );
      prsWithDiffs.push({ ...pr, diff });
    } catch {
      // Skip if we can't get the diff
    }
  }

  // Analyze diff patterns
  const diffPatterns: Record<string, { count: number; examples: PullRequest[] }> = {};

  for (const pr of prsWithDiffs) {
    if (!pr.diff) continue;

    // Categorize by type of change
    const patterns: string[] = [];

    if (pr.diff.includes('.md') && pr.diff.match(/^[-+]\s*#/m)) {
      patterns.push('markdown-heading-formatting');
    }
    if (pr.diff.match(/^[-+]\s*\*\*/m)) {
      patterns.push('markdown-bold-formatting');
    }
    if (pr.diff.match(/^[-+].*trailing\s*$/m) || pr.diff.match(/^[-+]\s+$/m)) {
      patterns.push('trailing-whitespace');
    }
    if (pr.diff.match(/^[-+].*\t/m)) {
      patterns.push('tabs-vs-spaces');
    }
    if (pr.diff.match(/^[-+].*console\.log/m)) {
      patterns.push('remove-console-log');
    }
    if (pr.diff.match(/^[-+].*TODO/m)) {
      patterns.push('todo-comments');
    }
    if (pr.diff.match(/^[-+].*eslint-disable/m)) {
      patterns.push('eslint-disable-comments');
    }
    if (pr.diff.match(/^[-+].*@ts-ignore/m)) {
      patterns.push('ts-ignore-comments');
    }
    if (pr.diff.match(/^[-+]import/m)) {
      patterns.push('import-changes');
    }
    if (pr.diff.match(/^[-+].*type\s*=/m) || pr.diff.match(/^[-+].*:\s*\w+\s*[;=]/m)) {
      patterns.push('type-annotations');
    }

    if (patterns.length === 0) {
      patterns.push('other');
    }

    for (const pattern of patterns) {
      if (!diffPatterns[pattern]) {
        diffPatterns[pattern] = { count: 0, examples: [] };
      }
      diffPatterns[pattern].count++;
      if (diffPatterns[pattern].examples.length < 3) {
        diffPatterns[pattern].examples.push(pr);
      }
    }
  }

  // Generate report
  let report = '# Q2: Autofix Candidates Analysis\n\n';
  report += `**Analysis Date:** ${new Date().toISOString()}\n\n`;
  report += `**Total Merged PRs:** ${allPRs.length}\n`;
  report += `**Vibecheck-related PRs:** ${vibecheckPRs.length}\n`;
  report += `**Small PRs Analyzed:** ${prsWithDiffs.length}\n\n`;

  report += '## Diff Pattern Analysis\n\n';
  report += 'These patterns appear frequently and could be autofix candidates:\n\n';

  const sortedPatterns = Object.entries(diffPatterns)
    .sort((a, b) => b[1].count - a[1].count);

  for (const [pattern, data] of sortedPatterns) {
    report += `### Pattern: \`${pattern}\` (${data.count} occurrences)\n\n`;

    if (data.examples.length > 0) {
      report += '**Example PRs:**\n';
      for (const pr of data.examples) {
        report += `- [${pr.repo.split('/')[1]}#${pr.number}](${pr.url}): ${pr.title}\n`;
      }
      report += '\n';

      // Show a sample diff
      const sampleDiff = data.examples[0].diff;
      if (sampleDiff && sampleDiff.length < 2000) {
        report += '**Sample diff:**\n```diff\n';
        report += sampleDiff.slice(0, 1500);
        report += '\n```\n\n';
      }
    }
  }

  report += '## Autofix Recommendations\n\n';
  report += '| Pattern | Priority | Autofix Feasibility |\n';
  report += '|---------|----------|--------------------|\n';

  const autofixPriority: Record<string, { priority: string; feasibility: string }> = {
    'markdown-heading-formatting': { priority: 'High', feasibility: 'Easy - regex-based' },
    'markdown-bold-formatting': { priority: 'Medium', feasibility: 'Easy - regex-based' },
    'trailing-whitespace': { priority: 'High', feasibility: 'Easy - trim lines' },
    'tabs-vs-spaces': { priority: 'Medium', feasibility: 'Easy - replace chars' },
    'remove-console-log': { priority: 'Medium', feasibility: 'Medium - AST-based' },
    'import-changes': { priority: 'Low', feasibility: 'Hard - context needed' },
    'type-annotations': { priority: 'Low', feasibility: 'Hard - type inference' },
  };

  for (const [pattern] of sortedPatterns) {
    const info = autofixPriority[pattern] || { priority: 'Low', feasibility: 'Needs analysis' };
    report += `| ${pattern} | ${info.priority} | ${info.feasibility} |\n`;
  }

  writeReport('q2-autofix-candidates.md', report);
  writeJson('q2-autofix-data.json', {
    totalPRs: allPRs.length,
    vibecheckPRs: vibecheckPRs.length,
    analyzedPRs: prsWithDiffs.length,
    patterns: Object.fromEntries(
      Object.entries(diffPatterns).map(([k, v]) => [k, v.count])
    ),
    prsWithDiffs: prsWithDiffs.map((pr) => ({
      ...pr,
      diff: pr.diff?.slice(0, 500), // Truncate diffs for JSON
    })),
  });
}

// ============================================================================
// Q3: Default Severity Configuration Review
// ============================================================================
async function analyzeQ3_DefaultSeverity(): Promise<void> {
  console.log('\n========================================');
  console.log('Q3: Reviewing Default Severity Config');
  console.log('========================================\n');

  // Check action.yml for default severity
  const actionYml = fs.readFileSync('action.yml', 'utf-8');

  // Check starter workflow
  let starterWorkflow = '';
  try {
    const starterFiles = fs.readdirSync('starter-workflow');
    for (const file of starterFiles) {
      if (file.endsWith('.yml') || file.endsWith('.yaml')) {
        starterWorkflow += `\n--- ${file} ---\n`;
        starterWorkflow += fs.readFileSync(path.join('starter-workflow', file), 'utf-8');
      }
    }
  } catch {
    console.log('  No starter-workflow directory found');
  }

  // Look for severity-related configs
  const severityMatches = actionYml.match(/severity|minimum.?severity|threshold/gi);
  const defaultMatches = actionYml.match(/default:\s*['"]?\w+['"]?/gi);

  let report = '# Q3: Default Severity Configuration Review\n\n';
  report += `**Analysis Date:** ${new Date().toISOString()}\n\n`;

  report += '## Current action.yml Configuration\n\n';
  report += '```yaml\n';

  // Extract the inputs section
  const inputsMatch = actionYml.match(/inputs:[\s\S]*?(?=outputs:|runs:|$)/);
  if (inputsMatch) {
    report += inputsMatch[0];
  }
  report += '\n```\n\n';

  report += '## Starter Workflow Configuration\n\n';
  if (starterWorkflow) {
    report += '```yaml\n';
    report += starterWorkflow;
    report += '\n```\n\n';
  } else {
    report += '*No starter workflow found*\n\n';
  }

  report += '## Recommendations\n\n';
  report += '1. **Default Severity:** Set `minimum_severity` default to `medium` in action.yml\n';
  report += '2. **Starter Workflow:** Ensure the install page generates workflows with `minimum_severity: medium`\n';
  report += '3. **Demo Repo Exception:** Keep vibecheck repo itself with lower threshold for demo purposes\n';
  report += '4. **Summary Table:** Add a note in the run summary showing suppressed lower-severity findings\n\n';

  report += '## Suggested Changes\n\n';
  report += '### action.yml\n';
  report += '```yaml\n';
  report += 'minimum_severity:\n';
  report += '  description: "Minimum severity level for creating issues"\n';
  report += '  required: false\n';
  report += '  default: "medium"\n';
  report += '```\n\n';

  report += '### Summary Table Enhancement\n';
  report += 'Add to the workflow run summary:\n';
  report += '```\n';
  report += '| Severity | Found | Issues Created | Suppressed |\n';
  report += '|----------|-------|----------------|------------|\n';
  report += '| Critical | 2     | 2              | 0          |\n';
  report += '| High     | 5     | 5              | 0          |\n';
  report += '| Medium   | 10    | 10             | 0          |\n';
  report += '| Low      | 15    | 0              | 15         |\n';
  report += '| Info     | 8     | 0              | 8          |\n';
  report += '```\n';

  writeReport('q3-default-severity.md', report);
}

// ============================================================================
// Q4: Useless Rules Analysis
// Look at closed-not-merged PRs to identify rules that should be downgraded
// ============================================================================
async function analyzeQ4_UselessRules(): Promise<void> {
  console.log('\n========================================');
  console.log('Q4: Analyzing Useless/Dismissed Rules');
  console.log('========================================\n');

  const closedNotMerged: PullRequest[] = [];

  for (const repo of REPOS) {
    console.log(`  Fetching closed PRs from ${repo}...`);
    const result = gh(
      'pr list --state closed --limit 200',
      {
        repo,
        json: 'number,title,body,state,labels,mergedAt,closedAt,url,additions,deletions,changedFiles',
      }
    );

    try {
      const prs = JSON.parse(result) as Array<{
        number: number;
        title: string;
        body: string;
        state: string;
        labels: Array<{ name: string }>;
        mergedAt: string | null;
        closedAt: string | null;
        url: string;
        additions: number;
        deletions: number;
        changedFiles: number;
      }>;

      // Filter for closed but NOT merged PRs
      const notMerged = prs.filter((pr) => !pr.mergedAt);

      for (const pr of notMerged) {
        closedNotMerged.push({
          ...pr,
          merged: false,
          labels: pr.labels.map((l) => l.name),
          repo,
        });
      }
    } catch {
      console.error(`  Failed to parse PRs from ${repo}`);
    }
  }

  console.log(`\n  Total closed-not-merged PRs: ${closedNotMerged.length}`);

  // Look for patterns in dismissed PRs
  const dismissedPatterns: Record<string, { count: number; prs: PullRequest[] }> = {};

  for (const pr of closedNotMerged) {
    // Extract potential rule or pattern from title/body
    const patterns: string[] = [];

    // Common styling rule patterns
    if (pr.title.match(/bold|strong/i)) patterns.push('bold-formatting');
    if (pr.title.match(/heading|header/i)) patterns.push('heading-formatting');
    if (pr.title.match(/whitespace|spacing/i)) patterns.push('whitespace');
    if (pr.title.match(/trailing/i)) patterns.push('trailing-whitespace');
    if (pr.title.match(/indent/i)) patterns.push('indentation');
    if (pr.title.match(/quote|quotation/i)) patterns.push('quote-style');
    if (pr.title.match(/semicolon/i)) patterns.push('semicolons');
    if (pr.title.match(/comma/i)) patterns.push('trailing-comma');
    if (pr.title.match(/line.?length|max.?len/i)) patterns.push('line-length');
    if (pr.title.match(/import.?order|sort.?import/i)) patterns.push('import-order');

    // Look for rule ID in body
    const ruleMatch = pr.body?.match(/Rule:\s*`?([^`\n]+)`?/);
    if (ruleMatch) {
      patterns.push(`rule:${ruleMatch[1]}`);
    }

    if (patterns.length === 0) {
      patterns.push('unknown');
    }

    for (const pattern of patterns) {
      if (!dismissedPatterns[pattern]) {
        dismissedPatterns[pattern] = { count: 0, prs: [] };
      }
      dismissedPatterns[pattern].count++;
      if (dismissedPatterns[pattern].prs.length < 5) {
        dismissedPatterns[pattern].prs.push(pr);
      }
    }
  }

  // Generate report
  let report = '# Q4: Useless/Dismissed Rules Analysis\n\n';
  report += `**Analysis Date:** ${new Date().toISOString()}\n\n`;
  report += `**Total Closed-Not-Merged PRs:** ${closedNotMerged.length}\n\n`;

  report += '## Frequently Dismissed Patterns\n\n';
  report += 'These patterns were often dismissed and may need severity downgrade:\n\n';

  const sortedPatterns = Object.entries(dismissedPatterns)
    .filter(([k]) => k !== 'unknown')
    .sort((a, b) => b[1].count - a[1].count);

  for (const [pattern, data] of sortedPatterns) {
    if (data.count >= 1) {
      report += `### Pattern: \`${pattern}\` (${data.count} dismissals)\n\n`;
      report += '**Example dismissed PRs:**\n';
      for (const pr of data.prs) {
        report += `- [${pr.repo.split('/')[1]}#${pr.number}](${pr.url}): ${pr.title}\n`;
      }
      report += '\n';
    }
  }

  report += '## Recommended Severity Changes\n\n';
  report += '| Rule/Pattern | Current | Recommended | Reason |\n';
  report += '|--------------|---------|-------------|--------|\n';

  const recommendations: Record<string, { current: string; recommended: string; reason: string }> = {
    'bold-formatting': { current: 'low', recommended: 'info', reason: 'Subjective style preference' },
    'heading-formatting': { current: 'low', recommended: 'info', reason: 'Often intentional styling' },
    'trailing-comma': { current: 'low', recommended: 'info', reason: 'Style preference varies' },
    'import-order': { current: 'low', recommended: 'info', reason: 'Cosmetic, not functional' },
    'line-length': { current: 'low', recommended: 'info', reason: 'Readability preference' },
  };

  for (const [pattern] of sortedPatterns) {
    const rec = recommendations[pattern];
    if (rec) {
      report += `| ${pattern} | ${rec.current} | ${rec.recommended} | ${rec.reason} |\n`;
    }
  }

  report += '\n## New Severity Level: "info"\n\n';
  report += 'Consider adding an "info" severity level below "low" for rules that:\n';
  report += '- Are purely stylistic preferences\n';
  report += '- Have high dismiss rates\n';
  report += '- Don\'t affect functionality or security\n\n';
  report += 'These would not create issues by default but would be shown in the summary.\n';

  writeReport('q4-useless-rules.md', report);
  writeJson('q4-dismissed-data.json', {
    totalDismissed: closedNotMerged.length,
    patterns: Object.fromEntries(
      Object.entries(dismissedPatterns).map(([k, v]) => [k, v.count])
    ),
    dismissedPRs: closedNotMerged.map((pr) => ({
      repo: pr.repo,
      number: pr.number,
      title: pr.title,
      url: pr.url,
      closedAt: pr.closedAt,
    })),
  });
}

// ============================================================================
// Q5: Build Breaks from Copilot PRs
// Check workflow runs for failures after Copilot merges
// ============================================================================
async function analyzeQ5_BuildBreaks(): Promise<void> {
  console.log('\n========================================');
  console.log('Q5: Analyzing Build Breaks from Copilot PRs');
  console.log('========================================\n');

  const allRuns: WorkflowRun[] = [];
  const failedRuns: WorkflowRun[] = [];

  for (const repo of REPOS) {
    console.log(`  Fetching workflow runs from ${repo}...`);
    const result = gh(
      'run list --limit 100',
      {
        repo,
        json: 'databaseId,name,conclusion,status,headBranch,headSha,event,createdAt,url',
      }
    );

    try {
      const runs = JSON.parse(result) as Array<{
        databaseId: number;
        name: string;
        conclusion: string;
        status: string;
        headBranch: string;
        headSha: string;
        event: string;
        createdAt: string;
        url: string;
      }>;

      for (const run of runs) {
        const workflowRun: WorkflowRun = {
          id: run.databaseId,
          name: run.name,
          conclusion: run.conclusion,
          status: run.status,
          headBranch: run.headBranch,
          headSha: run.headSha,
          event: run.event,
          createdAt: run.createdAt,
          url: run.url,
          repo,
        };
        allRuns.push(workflowRun);

        if (run.conclusion === 'failure') {
          failedRuns.push(workflowRun);
        }
      }
    } catch {
      console.error(`  Failed to parse runs from ${repo}`);
    }
  }

  console.log(`\n  Total workflow runs: ${allRuns.length}`);
  console.log(`  Failed runs: ${failedRuns.length}`);

  // For failed runs, try to correlate with recent merges
  const failuresWithContext: Array<{
    run: WorkflowRun;
    recentMerge?: PullRequest;
    failureLogs?: string;
  }> = [];

  for (const run of failedRuns.slice(0, 30)) {
    console.log(`  Checking context for failure in ${run.repo}...`);

    // Get recent merged PRs around the time of failure
    let recentMerge: PullRequest | undefined;
    try {
      const prsResult = gh(
        `pr list --state merged --limit 5 --base ${run.headBranch}`,
        {
          repo: run.repo,
          json: 'number,title,mergedAt,url,labels',
        }
      );
      const prs = JSON.parse(prsResult) as Array<{
        number: number;
        title: string;
        mergedAt: string;
        url: string;
        labels: Array<{ name: string }>;
      }>;

      // Find PR merged close to the failure time
      for (const pr of prs) {
        const mergeTime = new Date(pr.mergedAt).getTime();
        const runTime = new Date(run.createdAt).getTime();
        const diffHours = Math.abs(runTime - mergeTime) / (1000 * 60 * 60);

        if (diffHours < 1) {
          recentMerge = {
            number: pr.number,
            title: pr.title,
            mergedAt: pr.mergedAt,
            url: pr.url,
            labels: pr.labels.map((l) => l.name),
            body: '',
            state: 'closed',
            merged: true,
            closedAt: pr.mergedAt,
            repo: run.repo,
            additions: 0,
            deletions: 0,
            changedFiles: 0,
          };
          break;
        }
      }
    } catch {
      // Skip if we can't get PR info
    }

    failuresWithContext.push({
      run,
      recentMerge,
    });
  }

  // Categorize failures
  const failuresByRepo: Record<string, number> = {};
  const failuresFromCopilot: typeof failuresWithContext = [];
  const failuresOther: typeof failuresWithContext = [];

  for (const item of failuresWithContext) {
    const repo = item.run.repo;
    failuresByRepo[repo] = (failuresByRepo[repo] || 0) + 1;

    if (item.recentMerge) {
      const isCopilot = item.recentMerge.labels.some(
        (l) => l.includes('copilot') || l.includes('bot') || l.includes('vibecheck')
      ) || item.recentMerge.title.toLowerCase().includes('fix');

      if (isCopilot) {
        failuresFromCopilot.push(item);
      } else {
        failuresOther.push(item);
      }
    } else {
      failuresOther.push(item);
    }
  }

  // Generate report
  let report = '# Q5: Build Breaks Analysis\n\n';
  report += `**Analysis Date:** ${new Date().toISOString()}\n\n`;
  report += `**Total Workflow Runs Analyzed:** ${allRuns.length}\n`;
  report += `**Failed Runs:** ${failedRuns.length}\n`;
  report += `**Failures Potentially from Copilot PRs:** ${failuresFromCopilot.length}\n\n`;

  report += '## Failures by Repository\n\n';
  report += '| Repository | Failed Runs |\n';
  report += '|------------|-------------|\n';

  const sortedByRepo = Object.entries(failuresByRepo)
    .sort((a, b) => b[1] - a[1]);

  for (const [repo, count] of sortedByRepo) {
    report += `| ${repo.split('/')[1]} | ${count} |\n`;
  }

  report += '\n## Failures Potentially Caused by Copilot PRs\n\n';

  if (failuresFromCopilot.length === 0) {
    report += '*No failures clearly linked to Copilot PRs found*\n\n';
  } else {
    for (const item of failuresFromCopilot) {
      report += `### ${item.run.repo.split('/')[1]} - Run #${item.run.id}\n\n`;
      report += `- **Workflow:** ${item.run.name}\n`;
      report += `- **Branch:** ${item.run.headBranch}\n`;
      report += `- **Time:** ${item.run.createdAt}\n`;
      report += `- **Run URL:** ${item.run.url}\n`;

      if (item.recentMerge) {
        report += `- **Recent Merge:** [#${item.recentMerge.number}](${item.recentMerge.url}) - ${item.recentMerge.title}\n`;
      }
      report += '\n';
    }
  }

  report += '## Analysis & Recommendations\n\n';
  report += '### Common Failure Causes\n\n';
  report += '1. **Missing context:** Copilot may not have full project context when making fixes\n';
  report += '2. **No CI validation:** Some repos lack CI to catch issues before merge\n';
  report += '3. **Type errors:** TypeScript/type checking not run before merge\n';
  report += '4. **Test failures:** Tests not run or not comprehensive enough\n\n';

  report += '### Recommendations\n\n';
  report += '1. **Require CI checks:** Ensure all repos have CI workflows that run before merge\n';
  report += '2. **Add context to issues:** Include more context in vibecheck issues for Copilot\n';
  report += '3. **Suggested tests:** Include test suggestions in issues for critical changes\n';
  report += '4. **Post-merge validation:** Consider a post-merge workflow to catch regressions\n\n';

  report += '### Repos Needing CI\n\n';
  report += 'Repos with failures but potentially missing robust CI:\n\n';

  for (const [repo, count] of sortedByRepo) {
    if (count >= 2) {
      report += `- [ ] ${repo} (${count} failures)\n`;
    }
  }

  writeReport('q5-build-breaks.md', report);
  writeJson('q5-build-breaks-data.json', {
    totalRuns: allRuns.length,
    failedRuns: failedRuns.length,
    failuresFromCopilot: failuresFromCopilot.length,
    byRepo: failuresByRepo,
    failuresWithContext: failuresWithContext.map((item) => ({
      repo: item.run.repo,
      runId: item.run.id,
      workflow: item.run.name,
      conclusion: item.run.conclusion,
      branch: item.run.headBranch,
      createdAt: item.run.createdAt,
      url: item.run.url,
      recentMerge: item.recentMerge
        ? {
            number: item.recentMerge.number,
            title: item.recentMerge.title,
            url: item.recentMerge.url,
          }
        : null,
    })),
  });
}

// ============================================================================
// Main
// ============================================================================
async function main(): Promise<void> {
  console.log('='.repeat(50));
  console.log('Vibecheck Performance Analysis');
  console.log('='.repeat(50));
  console.log(`\nAnalyzing ${REPOS.length} repositories...\n`);

  // Parse command line args
  const args = process.argv.slice(2);
  const questionsArg = args.find((a) => a.startsWith('--question='));
  const questions = questionsArg
    ? questionsArg.split('=')[1].split(',').map(Number)
    : [1, 2, 3, 4, 5];

  // Verify gh is authenticated
  try {
    execSync('gh auth status', { encoding: 'utf-8' });
    console.log('GitHub CLI authenticated successfully.\n');
  } catch {
    console.error('Error: GitHub CLI not authenticated. Run `gh auth login` first.');
    process.exit(1);
  }

  ensureOutputDir();

  if (questions.includes(1)) {
    await analyzeQ1_BundleableIssues();
  }

  if (questions.includes(2)) {
    await analyzeQ2_AutofixCandidates();
  }

  if (questions.includes(3)) {
    await analyzeQ3_DefaultSeverity();
  }

  if (questions.includes(4)) {
    await analyzeQ4_UselessRules();
  }

  if (questions.includes(5)) {
    await analyzeQ5_BuildBreaks();
  }

  console.log('\n' + '='.repeat(50));
  console.log('Analysis Complete!');
  console.log('='.repeat(50));
  console.log(`\nReports written to: ${OUTPUT_DIR}/`);
  console.log('\nFiles generated:');

  const files = fs.readdirSync(OUTPUT_DIR);
  for (const file of files) {
    console.log(`  - ${file}`);
  }
}

main().catch(console.error);
